{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c4c621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "class LogisticRegressionGD:\n",
    "\tdef __init__(self, lr=0.1, epochs=1000, fit_intercept=True, verbose=False):\n",
    "\t\tself.lr = lr # learning rate\n",
    "\t\tself.epochs = epochs # number of iterations\n",
    "\t\tself.fit_intercept = fit_intercept # whether to add intercept (bias) (w0)\n",
    "\t\tself.verbose = verbose #if true, print loss during training\n",
    "\t\tself.coef_ = None # model parameters (weigths) (w) \n",
    "\n",
    "\tdef _add_intercept(self, X):\n",
    "\t\tif not self.fit_intercept:\n",
    "\t\t\treturn X\n",
    "\t\tintercept = np.ones((X.shape[0], 1))\n",
    "\t\treturn np.hstack((intercept, X))\n",
    "\n",
    "\tdef _sigmoid(self, z):\n",
    "\t\treturn 1 / (1 + np.exp(-z))\n",
    "\n",
    "\tdef fit(self, X, y):\n",
    "\t\tX = np.asarray(X, dtype=float)\n",
    "\t\ty = np.asarray(y, dtype=float).reshape(-1, 1)\n",
    "\t\tX = self._add_intercept(X)\n",
    "\t\tm, n = X.shape\n",
    "\t\t# weights init\n",
    "\t\tself.coef_ = np.random.uniform(-0.01, 0.01, size=(n, 1))\n",
    "\t\tfor epoch in range(self.epochs):\n",
    "\t\t\tz = X.dot(self.coef_)\n",
    "\t\t\th = self._sigmoid(z)\n",
    "\t\t\t# gradient\n",
    "\t\t\tgrad = (X.T.dot(h - y))\n",
    "\t\t\tself.coef_ -= self.lr * grad\n",
    "\n",
    "\t\treturn self\n",
    "\n",
    "\tdef predict_proba(self, X):\n",
    "\t\tX = np.asarray(X, dtype=float)\n",
    "\t\tX = self._add_intercept(X)\n",
    "\t\tproba = self._sigmoid(X.dot(self.coef_))\n",
    "\t\treturn proba.ravel()\n",
    "\n",
    "\tdef predict(self, X, threshold=0.5):\n",
    "\t\treturn (self.predict_proba(X) >= threshold).astype(int)\n",
    "\n",
    "# Fonctions utilitaires de prétraitement\n",
    "def load_and_preprocess(path=None, label_col='default', test_size=0.2, random_state=42):\n",
    "\tif path and os.path.exists(path):\n",
    "\t\tdf = pd.read_csv(path)\n",
    "\t\tif label_col not in df.columns:\n",
    "\t\t\traise ValueError(f\"Label column '{label_col}' not found in CSV.\")\n",
    "\t\t# Séparer features / label\n",
    "\t\ty = df[label_col].astype(int)\n",
    "\t\tX = df.drop(columns=[label_col])\n",
    "\t\t# Remplir NA et encoder categoricals\n",
    "\t\tX = X.fillna(X.median(numeric_only=True))\n",
    "\t\tX = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "\n",
    "\t# Standardisation\n",
    "\tscaler = StandardScaler()\n",
    "\tX_scaled = scaler.fit_transform(X.values)\n",
    "\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X_scaled, y.values, test_size=test_size,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\trandom_state=random_state, stratify=y.values)\n",
    "\treturn X_train, X_test, y_train, y_test, scaler\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "\ty_pred = model.predict(X_test)\n",
    "\ty_prob = model.predict_proba(X_test)\n",
    "\tmetrics = {\n",
    "\t\t'accuracy': float(accuracy_score(y_test, y_pred)),\n",
    "\t\t'precision': float(precision_score(y_test, y_pred, zero_division=0)),\n",
    "\t\t'recall': float(recall_score(y_test, y_pred, zero_division=0)),\n",
    "\t\t'roc_auc': float(roc_auc_score(y_test, y_prob))\n",
    "\t}\n",
    "\treturn metrics\n",
    "\n",
    "def main():\n",
    "\tparser = argparse.ArgumentParser(description=\"Régression logistique pour défaut de crédit\")\n",
    "\tparser.add_argument('--data', type=str, default=None, help='Chemin vers le CSV (doit contenir la colonne \"default\")')\n",
    "\tparser.add_argument('--label', type=str, default='default', help='Nom de la colonne label dans le CSV')\n",
    "\tparser.add_argument('--lr', type=float, default=0.1)\n",
    "\tparser.add_argument('--epochs', type=int, default=1000)\n",
    "\tparser.add_argument('--verbose', action='store_true')\n",
    "\targs = parser.parse_args()\n",
    "\n",
    "\tX_train, X_test, y_train, y_test, scaler = load_and_preprocess(args.data, label_col=args.label)\n",
    "\tmodel = LogisticRegressionGD(lr=args.lr, epochs=args.epochs, verbose=args.verbose)\n",
    "\tmodel.fit(X_train, y_train)\n",
    "\tmetrics = evaluate_model(model, X_test, y_test)\n",
    "\tprint(\"Évaluation du modèle:\")\n",
    "\tfor k, v in metrics.items():\n",
    "\t\tprint(f\"  {k}: {v:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tmain()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
